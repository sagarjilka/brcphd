{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data Analytics in Python\n",
    "\n",
    "## Dr. Sagar Jilka\n",
    "### BRC PhD Teaching, 5th Feb 2019\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After completing this course, you should be able to:\n",
    "1.\tDemonstrate familiarity with the Python language and the Jupyter Notebook environment\n",
    "\n",
    "2.\tUnderstand and demonstrate familiarity with working with raw data, e.g.\n",
    "a.\tMerging datasets\n",
    "b.\tWorking with missing data\n",
    "c.\tAggregating data\n",
    "d.\tBasic plotting\n",
    "\n",
    "3.\tSummarize and analyse data in Python, based on statistics already familiar to you, e.g.:\n",
    "a.\tObtaining descriptive statistics (mean, median, SD, etc)\n",
    "b.\tT-test (+sig., df)\n",
    "c.\tCorrelation (+sig., r)\n",
    "d.\tANOVA\n",
    "\n",
    "4.\tExplore data through familiar and advanced visualisation techniques, including:\n",
    "a.\tPreviously introduced histograms\n",
    "b.\tNew ways of data visualisation and graph manipulation\n",
    "\n",
    "5.\tExplore a deeper understanding of industry level data science, including Learning the basics about machine learning and building machine learning models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# What is Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python is a powerful programming language created by Guido van Rossum. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![title](..\\Sagar_Guido.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has simple easy-to-use syntax:\n",
    "\n",
    "Lets take a quick look at the “Zen of Python”\n",
    "\n",
    "type import this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import this"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "See here for cool interpretation --> https://speakerdeck.com/bhoomika10/the-zen-of-python?slide=9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading Python "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can downloaded from www.python.org\n",
    "\n",
    "However, best to download a scientific python distribution such as anaconda https://www.anaconda.com/download\n",
    "Choose Python 3 (Python 2.7 and 3.0 have a few subtle differences in syntax – 3.0 has more help available online so easier to use, 2 will also soon stop being supported... :(\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is an IDE?\n",
    "\n",
    "IDE = Integrated Development Environment\n",
    "\n",
    "A program for writing/running scripts\n",
    "\n",
    "Makes it easy to write and run code in one program\n",
    "\n",
    "‘Jupyter’ is a good IDE that comes with the Anaconda installation, as you can see ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1) Basic Python "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables\n",
    "\n",
    "A variable stores some sort of data\n",
    "\n",
    "The value of a variable is assigned using a single =\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_variable = \"Hello folks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_variable = 1\n",
    "myVar = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_variable + myVar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Heads up - naming!\n",
    "\n",
    "If you want to name give a variable a name containing multiple words there are two accepted methods:\n",
    "\n",
    "camelCase = using uppercase letters \n",
    "using_underscores\n",
    "\n",
    "Personal preference – although official Python style suggests using underscores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Types\n",
    "\n",
    "Basic data types include strings, integers, floats\n",
    "\n",
    "String = text (Indicated by wrapping the text in quotes (‘’, or “”) E.g. “hello world”)\n",
    "\n",
    "Integer = whole numbers (E.g. 5)\n",
    "\n",
    "Float = numbers with decimals (E.g. 2.351)\n",
    "\n",
    "Boolean = True or False (Use the command True or False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myVar2 = \"Twenty\"\n",
    "myVar3 = 20\n",
    "myVar4 = 20.1\n",
    "myVar5 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(myVar4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maths\n",
    "\n",
    "Python can perform mathematical operations on integers or floats\n",
    "\n",
    "Add +\n",
    "\n",
    "Subtract –\n",
    "\n",
    "Divide / \n",
    "\n",
    "Multiply *\n",
    "\n",
    "Modulo % (gives remainder of a division)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick tasks 1 & 2\n",
    "\n",
    "(1) Create 4 variables representing a string, an integer, a float, and a Boolean\n",
    "\n",
    "(2) A chocolate factory packs 20 bars into each box. Today they produced 1000 bars of chocolate. Write an algorithm to calculate and output the number of full boxes produced in a day.\n",
    "\n",
    "\n",
    "(Reminder: string = text, integer = whole number, float = decimals, boolean = True/False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 in simple form\n",
    "numberOfBars = 1000\n",
    "numberOfBoxes = (numberOfBars / 20)\n",
    "print(numberOfBoxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 in slightly more complicated form.\n",
    "\n",
    "numberOfBars = int(input(\"Enter number of bars produced : \"))\n",
    "numberOfBoxes = (numberOfBars/20) \n",
    "print(\"\\n**\", numberOfBoxes , \"'full' boxes have been produced.**\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lists, dictionaries, tuples\n",
    "\n",
    "Lists are what they seem - a list of values. Each one of them is numbered, starting from zero. You can remove values from the list, and add new values to the end.\n",
    "\n",
    "Tuples are just like lists, but you can't change their values. The values that you give it first up, are the values that you are stuck with for the rest of the program. Again, each value is numbered starting from zero. \n",
    "\n",
    "Dictionaries are similar to what their name suggests - a dictionary. In a dictionary, you have an 'index' of words, and for each of them a definition. In python, the word is called a 'key', and the definition a 'value'. The values in a dictionary aren't numbered - they aren't in any specific order, either - the key does the same thing. You can add, remove, and modify the values in dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myList = [1, 2, 3, 4, 5, \"Captain\", \"America\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(myList)\n",
    "myList[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myList.append(\"Avengers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myList2 = [975, 2454, 'Hello']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myTuple = ('January','February','March','April','May','June','July','August','September','October','November','  December')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#myTuple.append('sadf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myTuple[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Make the phone book:\n",
    "phonebook = {'Andrew Parson':8806336, \\\n",
    "'Emily Everett':6784346, 'Peter Power':7658344, \\\n",
    "'Lewis Lame':1122345}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phonebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phonebook['Gingerbread Man'] = 1234567"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phonebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Good website: http://sthurlow.com/python/lesson06/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in myList:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) Working with data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python has many powerful packages to help us analyse data. The most commonly used are Numpy and Pandas.\n",
    "\n",
    "Pandas stands for “Python Data Analysis Library”. It's great for dealing with spreadsheet-style data – by creating ‘Dataframes’. You can then easily select columns from datasets and apply functions to them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pandas \n",
    "\n",
    "Now we will do some actual analysis with real life data using Pandas. The plan is:\n",
    "\n",
    "1) Read in a csv file for analysis\n",
    "\n",
    "2) Understand pandas and dataframes\n",
    "\n",
    "3) Clean and pre-process data (e.g. fill missing values)\n",
    "\n",
    "4) Compute basic stats\n",
    "\n",
    "5) Merge datasets\n",
    "\n",
    "6) Aggregate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your Anaconda Python distribution comes with Pandas ready to use. All you have to do to use it is ‘import’ pandas. \n",
    "# Common abbreviation to use is ‘pd’ as below. \n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# you can see your current path by typing !cd\n",
    "!cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# explore pandas read_ function. You can import all sorts of files, e.g. excel, html, sql etc...\n",
    "# explore the function arguments by hitting tab inside the green parantheses.\n",
    "# the below function will import the data based on your arguments and create a dataframe assigned to the variable called ratings\n",
    "\n",
    "df = pd.read_csv(\"brain_size_clindata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# you can view your new dataframe by typing the variable name\n",
    "#df\n",
    "\n",
    "# you can view the first five rows by typing .head() after the variable name\n",
    "#df.head()\n",
    "\n",
    "# you can view the last five rows by typing .tail() after the variable name\n",
    "#df.tail()\n",
    "\n",
    "# Slicing: you can select a particular portion of the dataframe (i.e. slicing) by telling python which rows you want to slice inside []\n",
    "#df[22:25]\n",
    "\n",
    "# Experiment with slicing e.g. df[:30] vs. df[30::2]\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now we need to import the ppt information dataset\n",
    "\n",
    "df2 = pd.read_csv(\"brain_size_ppts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use slicing to remove the random 'unnamed:0' column from df2\n",
    "#df2 = df2[['ppt_id' , 'Gender' , 'Weight' , 'Height']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging Datasets\n",
    "\n",
    "Explain about merges here - have a look at the SQL images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create one merged DataFrame\n",
    "df_all = df.merge(df2, on = ['ppt_id', 'Unnamed: 0'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Great, looks like it has worked (no errors!)\n",
    "# How cna we take a look? What do we need to type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lets keep only the columns we need. You can 'filter out' columns by using the below syntax\n",
    "\n",
    "df_all = df_all[['ppt_id', 'FSIQ', 'VIQ', 'PIQ', 'MRI_Count', 'Gender', 'Weight', 'Height', 'Diagnosed' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If you had column names that were different, you could rename them:\n",
    "\n",
    "# df.rename(columns={'pptId': 'ppt_id'}, inplace=True)\n",
    "\n",
    "# Note the use of a dictionary there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working with missing data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain the fillna method and various ways to fillna...\n",
    "\n",
    "You could also just df_all.drop, but this would remove important data. \n",
    "\n",
    "How else could you impute missing cell values?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Consider\n",
    "\n",
    "# fillna(0) fillna(\"MissingValue\") fillna(-99) etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_all.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum up the output above to show the total number of missing values per column\n",
    "\n",
    "df_all.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows the rows where there are missing values\n",
    "\n",
    "df_all[df_all.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You could run this code below, which would fill the missing Weight values with the whole\n",
    "# column means. Is this a good idea? Why, why not?\n",
    "\n",
    "#df_all[\"Weight\"].fillna(df_all[\"Weight\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.groupby(\"Gender\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_all.Weight.fillna(166.444444, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all.Height.fillna(413.052632, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have filled the missing values, you will see that there are no rows with\n",
    "# missing values\n",
    "\n",
    "df_all[df_all.isnull().any(axis=1)]\n",
    "\n",
    "# Can anyone guess what the axis argument is doing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now consider if you had a HUGE dataset with multiple columns and multiple groups (i.e\n",
    "# more than just male and female). It would take time to fillna\n",
    "\n",
    "df_all[\"Weight\"].fillna(df_all.groupby(\"Gender\")[\"Weight\"].transform(\"mean\"), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[df_all.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# And now lets fill missing Height values\n",
    "\n",
    "df_all[\"Height\"].fillna(df_all.groupby(\"Gender\")[\"Height\"].transform(\"mean\"), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And voila... no more missing values!\n",
    "\n",
    "df_all[df_all.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregating data \n",
    "\n",
    "One of my favourite pandas functions is the groupby() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment with .median, .describe, consider adding other categorical variables in the\n",
    "# groupby and then aggregating. \n",
    "\n",
    "# Introduce the .to_clipboard() function, and the transpose function, which are useful \n",
    "# when writing a paper.\n",
    "\n",
    "\n",
    "df_all.groupby(\"Gender\").mean()#.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if you want to investigate two categorical variables?\n",
    "\n",
    "cols_to_grpby = ['Gender', 'Diagnosed']\n",
    "\n",
    "df_all.groupby(cols_to_grpby).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.groupby(cols_to_grpby).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_all.groupby(cols_to_grpby).describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare your tables for publication? \n",
    "# I copy to clipboard and then format in Excel..\n",
    "\n",
    "df_all.groupby(cols_to_grpby).describe().T.to_clipboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with basic bar/line plots, learning seaborn methods, and then something interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we need to import more libraries, notably matplotlib and seaborn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import seaborn as sns\n",
    "\n",
    "#note the magic function below. This is important because it will allow the plots you\n",
    "#create to appear here in the notebook.\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = df_all[\"FSIQ\"] # you can replace FSIQ with any other column.. try it\n",
    "plt.hist(xx, bins = 10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets consider the seaborn library, which we will use as seaborn is generally easier, and make the images much better!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_all['Weight'], kde=False, rug=True, bins = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to investigate:\n",
    "\n",
    "\n",
    "(1) Differences in IQ/brain size between men and women?\n",
    "\n",
    "(2) Any correlations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Now is a good time to explore the seaborn library. \n",
    "I will show you how to use the examples and apply them to your work **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://seaborn.pydata.org/generated/seaborn.catplot.html?highlight=catplot#seaborn.catplot\n",
    "\n",
    "sns.catplot(data=df_all,\n",
    "            x=\"Gender\", \n",
    "            y=\"PIQ\", \n",
    "            #palette={\"Male\": \"blue\", \"Female\": \"pink\"}, # you can also specify colours!\n",
    "            kind=\"strip\"); #experiment with different kinds, e.g. “bar”, “strip”, “swarm”, “box”, “violin”, or “boxen”.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets add another categorical variable to the graph:\n",
    "# We want to add Diagnosed or not to the figure\n",
    "\n",
    "sns.catplot(data=df_all,\n",
    "            x=\"Gender\", \n",
    "            y=\"PIQ\", \n",
    "            hue = \"Diagnosed\",\n",
    "            #palette={\"Male\": \"blue\", \"Female\": \"pink\"}, # you can also specify colours!\n",
    "            kind=\"bar\"); #experiment with different kinds, e.g. “bar”, “strip”, “swarm”, “box”, “violin”, or “boxen”.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets do some correlations and make a correlation matrix\n",
    "\n",
    "corr = df_all.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets add some colour to help differentiate between variables\n",
    "\n",
    "corr.style.background_gradient()#.set_precision(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to calculate pearson r then you can use the function below, don't worry about the code, I will show you to implement it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_pvalues(df):\n",
    "    df = df.dropna()._get_numeric_data()\n",
    "    dfcols = pd.DataFrame(columns=df.columns)\n",
    "    pvalues = dfcols.transpose().join(dfcols, how='outer')\n",
    "    for r in df.columns:\n",
    "        for c in df.columns:\n",
    "            pvalues[r][c] = round(pearsonr(df[r], df[c])[1], 4)\n",
    "    return pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_pvalues(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Exploring scatterplots\n",
    "\n",
    "#https://seaborn.pydata.org/generated/seaborn.scatterplot.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"FSIQ\", y=\"PIQ\", data=df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(10,8))\n",
    "\n",
    "sns.scatterplot(data=df_all,\n",
    "                x=\"FSIQ\", \n",
    "                y=\"PIQ\", \n",
    "                hue=\"Gender\",) #experiment with different categorical 'hues', e.g. Diagnosed\n",
    "                #size = \"Height\") # Explore what the size argument does...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving your figures for publication\n",
    "\n",
    "# assign the code to a random variable (something like g = )\n",
    "\n",
    "g = sns.scatterplot(data=df_all,\n",
    "                x=\"FSIQ\", \n",
    "                y=\"PIQ\", \n",
    "                hue=\"Gender\",) #experiment with different categorical 'hues', e.g. Diagnosed\n",
    "                #size = \"Height\") # Explore what the size argument does...\n",
    "\n",
    "    \n",
    "# Use the savefig argument and provide a filename, such as figure1.png\n",
    "# You can use keyword arguments based on your journal's submission requirements\n",
    "# For exmaple, for the British Journal of Psychiatry (https://www.cambridge.org/core/services/authors/journals/journals-artwork-guide)\n",
    "# they want images at 300dpi and ideally in TIFF format, so you can save your figure appropriately\n",
    "# So check with your submission guidelines and provide the appropriate arguments\n",
    "# Tip: for posters, you might want to use the transparancy argument\n",
    "\n",
    "#g.figure.savefig(\"output.tiff\", dpi = 300) #transparency = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### IV = Gender (Male, Female), also Diagnoses (Yes, No)\n",
    "##### DV = IQ Scores (FSIQ, VIQ, PIQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to test if there is a difference in IQ measures between genders? Or \"diagnosed\"? What tests can we use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# There are two libraries (that i know of anyway) to do stats in Python - scipy and statsmodels\n",
    "\n",
    "# Lets start with scipy and we will compare the syntax and output with statsmodel\n",
    "\n",
    "# Import as below...\n",
    "\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumption of normality\n",
    "\n",
    "#### Shapiro-wilk test (output = w test statistic, p value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.shapiro(df_all[\"FSIQ\"])\n",
    "\n",
    "# consider the difference between the above and the below commented code:\n",
    "\n",
    "#stats.shapiro(df_all[\"FSIQ\"][df_all['Gender'] == 'Male'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also test other DVs\n",
    "\n",
    "print(stats.shapiro(df_all[\"PIQ\"]))\n",
    "print(stats.shapiro(df_all[\"VIQ\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets make some Q-Q Plots\n",
    "stats.probplot(df_all[\"FSIQ\"],plot= plt)\n",
    "\n",
    "# Give your figure a title\n",
    "plt.title(\"FSIQ Q-Q Plot\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets make a loop and test all three of our IQ DVs in one go:\n",
    "\n",
    "# First make a list variable called cols with your DVs in it\n",
    "cols = ['FSIQ', 'PIQ', 'VIQ']\n",
    "\n",
    "# Then make a loop using the for statement. This will loop through every item in cols\n",
    "# and do you tell it to do, in this case, we are telling it to do stats.shapiro\n",
    "for i in cols:\n",
    "    print(i)\n",
    "    print(stats.shapiro(df_all[i][df_all['Gender'] == 'Male']))\n",
    "    \n",
    "for i in cols:\n",
    "    stats.probplot(df_all[i][df_all['Gender'] == 'Male'], plot= plt)\n",
    "    plt.title(\"Mental Health Q-Q Plot\")\n",
    "    \n",
    "print(\"\\n\\nAssumption of normality is violated as (all) the p-values are < than 0.05.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Levene's Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "levene_1 = df_all[\"PIQ\"][df_all['Gender'] == 'Male']\n",
    "levene_2 = df_all[\"PIQ\"][df_all['Gender'] == 'Female']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.levene(levene_1, levene_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets make a quick loop so we can run a levene's test on all our DVs\n",
    "\n",
    "for i in cols:\n",
    "    print(i , ':' , stats.levene(df_all[i][df_all['Gender'] == 'Male'], \n",
    "                                 df_all[i][df_all['Gender'] == 'Female']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ANOVA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will statsmodels because the output is better (more readable)\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Documentation here: https://www.statsmodels.org/stable/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = ols(\"FSIQ ~ C(Gender)\", data = df_all).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The adfsaf asdf , F(%f, %f) = %f , p = %f\" %(results.df_resid, \n",
    "                                                    results.df_model,\n",
    "                                                    results.fvalue, \n",
    "                                                    results.f_pvalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Consider writing a function that writes out your results section for you!\n",
    "# You need to find the following bits of info from the above...\n",
    "\n",
    "# F(df effect, df error) = F-value, MSE = mean-square error, p-value\". \n",
    "# e.g., \"IQ scores did/didn't differ significantly between genders, F(X,XX) = XXXX, MSE = XXX, p = XXX.\n",
    "\n",
    "# You can find each of those individual bits of data by typing results. then hit tab and \n",
    "# you will be able to see all the methods that the results object contains!\n",
    "\n",
    "# For instance:\n",
    "\n",
    "#print(results.df_model)\n",
    "#print(results.df_resid)\n",
    "#print(results.fvalue)\n",
    "#print(results.f_pvalue)\n",
    "#print(results.mse_total)\n",
    "\n",
    "# Now you jsut need to put all that together..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_output(dv, iv, df):\n",
    "\n",
    "        # So first make two variables that represent the IV and DV\n",
    "        x = (\"~ C(%s)\" %iv)\n",
    "        y = str(dv + x)\n",
    "        \n",
    "        # Then make the model.\n",
    "        results = ols(y, data=df).fit()\n",
    "        \n",
    "        # Then make a statement which prints out an appropriate statement \n",
    "        # based on the p-value...\n",
    "        \n",
    "        if results.f_pvalue > 0.05:\n",
    "            \n",
    "            print(\"A one-way ANOVA was conducted to compare difference in %s between %s. We found no significant difference between %s,\\\n",
    "                   F(%f, %f) = %f , p = %f\" %(dv, iv, iv,\n",
    "                                              results.df_model, \n",
    "                                              results.df_resid,\n",
    "                                              results.fvalue, \n",
    "                                              results.f_pvalue))\n",
    "        else:\n",
    "            print(\"A one-way ANOVA was conducted to compare difference in %s between %s. We found a significant difference between %s\\\n",
    "                   F(%f, %f) = %f , p = %f\" %(dv, iv, iv,\n",
    "                                              results.df_model, \n",
    "                                              results.df_resid,\n",
    "                                              results.fvalue, \n",
    "                                              results.f_pvalue))\n",
    "        \n",
    "        # If you fancy, you can tell the function to return an output such as the\n",
    "        # summary table, if so, uncomment the bottom bit below...\n",
    "        \n",
    "        #return results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you can call your function and give it your arguments like below...\n",
    "\n",
    "res_output(dv = \"VIQ\", \n",
    "           iv = \"Gender\", \n",
    "           df = df_all) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning - Would you survive the titanic?!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "To learn the concept of machine learning (ML), lets predict if YOU would survive the titanic based on the passenger and survival history.\n",
    "\n",
    "Python has a powerful library called sci-kit learn (sklearn) which does everything for you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load up the titanic3.xls into a pandas dataframe\n",
    "\n",
    "titanic_df = pd.read_excel('titanic3.xls', 'titanic3', na_values=['NA'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns refer to:\n",
    "\n",
    "- survival - Survival (0 = No; 1 = Yes)\n",
    "- pclass - Passenger Class (1 = 1st; 2 = 2nd; 3 = 3rd)\n",
    "- name - Name\n",
    "- sex - Sex\n",
    "- age - Age\n",
    "- sibsp - Number of Siblings/Spouses Aboard\n",
    "- parch - Number of Parents/Children Aboard\n",
    "- ticket - Ticket Number\n",
    "- fare - Passenger Fare\n",
    "- cabin - Cabin\n",
    "- embarked - Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)\n",
    "- boat - Lifeboat (if survived)\n",
    "- body - Body number (if did not survive and body was recovered)\n",
    "- home.dest - home destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Firstly lets explore the dataset,\n",
    "\n",
    "What was the survival rate?\n",
    "Can you make a table of gender vs. class and survival.\n",
    "Can you plot what you are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df['survived'].mean()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.groupby(['sex', 'pclass']).mean()['survived']*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.factorplot(data = titanic_df, x = 'sibsp', y = 'parch', aspect = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "What features (aka columns) do you think will be important for us to predict survival?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can drop some columns..\n",
    "\n",
    "titanic_df = titanic_df.drop(['body','cabin','boat', 'home.dest' , 'embarked'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lets clean the data in prep for ML...\n",
    "# ML models works only with numbers, can anyone see an issue with the dataset?\n",
    "\n",
    "titanic_df['sex'] = titanic_df['sex'].map({'female': 1, 'male': 0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ML also doesn't work with missing values, so we can impute them...\n",
    "# for this demonstration, I'm just going to get rid of empty data\n",
    "\n",
    "titanic_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets see if we have any missing rows...\n",
    "\n",
    "titanic_df[titanic_df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets create our features and response variables (X and y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# store the feature matrix (X) and response vector (y)\n",
    "\n",
    "X = titanic_df[['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare']]\n",
    "\n",
    "y = titanic_df['survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check the shapes of X and y to make sure the number of rows match up\n",
    "# why is this important?\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets look at our features.. can anyone see what's wrong here?\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lets look at y\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 4 steps to ML in Python... IIFP\n",
    "\n",
    "#### (1) Import\n",
    "#### (2) Instantiate\n",
    "#### (3) Fit\n",
    "#### (4) Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (1) import the class, in this case we will use k-neighbours\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (2) instantiate the model (with the default parameters)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=25)#weights = 'uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (3) fit the model with data (occurs in-place)\n",
    "\n",
    "knn.fit(X, y)\n",
    "#knn.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (4) Predict\n",
    "# Enter your data in the same order of the X columns:\n",
    "# There should be 6 numbers:\n",
    "\n",
    "knn.predict([[2, 0, 32, 0, 1, 32]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the model has predicted that the new observation’s class is 0 (i.e. I wouldn't have survived!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even look at the probabilities the model assigned to each class to see how confident it is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.predict_proba([[2, 0, 32, 0, 1, 32]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to this result, the model predicted that the observation was dead with a ~52% probability and survive with a ~48% probability. \n",
    "\n",
    "Because the observation had a greater probability of being dead, it predicted that class for the observation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try another model (Random Forest) but you can experiment with many more..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Random Forest\n",
    "- Perceptron\n",
    "- SGDC\n",
    "- Decision tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First (1) import\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.linear_model import Perceptron\n",
    "#from sklearn.linear_model import SGDClassifier\n",
    "#from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Then (2) instantiate\n",
    "random_forest = RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Then (3) fit\n",
    "\n",
    "random_forest.fit(X, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then (4) predict\n",
    "\n",
    "random_forest.predict([[2, 0, 32, 0, 1, 35.23]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest.predict_proba([[2, 0, 32, 0, 1, 35.23]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see which of our features were the most important to this model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dataframe\n",
    "importances = pd.DataFrame({'feature':X.columns,\n",
    "                            'importance': random_forest.feature_importances_})\n",
    "\n",
    "# Sort the value, set the index \n",
    "importances = importances.sort_values('importance',ascending=False).set_index('feature')\n",
    "\n",
    "# Display the first 15 rows of the dataframe\n",
    "importances.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.296 + 0.286 + 0.258 + 0.083 + 0.041 +0.036"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances.importance.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
